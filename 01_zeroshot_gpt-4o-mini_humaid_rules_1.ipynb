{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89c8037-b798-47c0-b5fc-809d2fb29054",
   "metadata": {},
   "source": [
    "# 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7212cc3-d5b3-4290-acad-06ac94d48009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "from humaidclf import run_experiment\n",
    "from humaidclf import build_token_index               # from budget.py\n",
    "from humaidclf.batch import use_api_key_env           # context manager for key switching\n",
    "from rules import RULES_1\n",
    "\n",
    "# --- config ---\n",
    "BASE = Path(\"Dataset/HumAID\")\n",
    "SPLITS = [\"train\"]             # or [\"train\",\"dev\",\"test\"]\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "RULES = RULES_1\n",
    "TAG = \"modeS-RULES1\"\n",
    "DRYRUN_N = 20\n",
    "POLL_SECS = 300\n",
    "DO_ANALYSIS = True\n",
    "OUT_ROOT = \"runs\"\n",
    "\n",
    "BATCH_TOKEN_LIMIT = 2_000_000  # Tier-1 cap\n",
    "SAFETY_MARGIN = 0.90           # 10% headroom\n",
    "MAX_OUTPUT_TOKENS = 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035230b7-67ed-4e79-9733-e9922d81c72a",
   "metadata": {},
   "source": [
    "# 1) Discover datasets (events/splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c5a9e3-e490-4b41-b9e5-2d31bfe9150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>split</th>\n",
       "      <th>tsv</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>avg_req_tokens</th>\n",
       "      <th>est_total_tokens</th>\n",
       "      <th>fits_cap</th>\n",
       "      <th>limit_used_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kaikoura_earthquake_2016</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\kaikoura_earthquake_2016\\kaikou...</td>\n",
       "      <td>1536</td>\n",
       "      <td>440</td>\n",
       "      <td>675840</td>\n",
       "      <td>True</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canada_wildfires_2016</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\canada_wildfires_2016\\canada_wi...</td>\n",
       "      <td>1569</td>\n",
       "      <td>439</td>\n",
       "      <td>688791</td>\n",
       "      <td>True</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cyclone_idai_2019</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\cyclone_idai_2019\\cyclone_idai_...</td>\n",
       "      <td>2753</td>\n",
       "      <td>461</td>\n",
       "      <td>1269133</td>\n",
       "      <td>True</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hurricane_florence_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\hurricane_florence_2018\\hurrica...</td>\n",
       "      <td>4384</td>\n",
       "      <td>455</td>\n",
       "      <td>1994720</td>\n",
       "      <td>False</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hurricane_maria_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\hurricane_maria_2017\\hurricane_...</td>\n",
       "      <td>5094</td>\n",
       "      <td>442</td>\n",
       "      <td>2251548</td>\n",
       "      <td>False</td>\n",
       "      <td>112.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>california_wildfires_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\california_wildfires_2018\\calif...</td>\n",
       "      <td>5163</td>\n",
       "      <td>451</td>\n",
       "      <td>2328513</td>\n",
       "      <td>False</td>\n",
       "      <td>116.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hurricane_dorian_2019</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\hurricane_dorian_2019\\hurricane...</td>\n",
       "      <td>5329</td>\n",
       "      <td>455</td>\n",
       "      <td>2424695</td>\n",
       "      <td>False</td>\n",
       "      <td>121.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kerala_floods_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\kerala_floods_2018\\kerala_flood...</td>\n",
       "      <td>5588</td>\n",
       "      <td>460</td>\n",
       "      <td>2570480</td>\n",
       "      <td>False</td>\n",
       "      <td>128.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hurricane_harvey_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\hurricane_harvey_2017\\hurricane...</td>\n",
       "      <td>6378</td>\n",
       "      <td>440</td>\n",
       "      <td>2806320</td>\n",
       "      <td>False</td>\n",
       "      <td>140.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurricane_irma_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>Dataset\\HumAID\\hurricane_irma_2017\\hurricane_i...</td>\n",
       "      <td>6579</td>\n",
       "      <td>440</td>\n",
       "      <td>2894760</td>\n",
       "      <td>False</td>\n",
       "      <td>144.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       event  split  \\\n",
       "8   kaikoura_earthquake_2016  train   \n",
       "1      canada_wildfires_2016  train   \n",
       "2          cyclone_idai_2019  train   \n",
       "4    hurricane_florence_2018  train   \n",
       "7       hurricane_maria_2017  train   \n",
       "0  california_wildfires_2018  train   \n",
       "3      hurricane_dorian_2019  train   \n",
       "9         kerala_floods_2018  train   \n",
       "5      hurricane_harvey_2017  train   \n",
       "6        hurricane_irma_2017  train   \n",
       "\n",
       "                                                 tsv  num_rows  \\\n",
       "8  Dataset\\HumAID\\kaikoura_earthquake_2016\\kaikou...      1536   \n",
       "1  Dataset\\HumAID\\canada_wildfires_2016\\canada_wi...      1569   \n",
       "2  Dataset\\HumAID\\cyclone_idai_2019\\cyclone_idai_...      2753   \n",
       "4  Dataset\\HumAID\\hurricane_florence_2018\\hurrica...      4384   \n",
       "7  Dataset\\HumAID\\hurricane_maria_2017\\hurricane_...      5094   \n",
       "0  Dataset\\HumAID\\california_wildfires_2018\\calif...      5163   \n",
       "3  Dataset\\HumAID\\hurricane_dorian_2019\\hurricane...      5329   \n",
       "9  Dataset\\HumAID\\kerala_floods_2018\\kerala_flood...      5588   \n",
       "5  Dataset\\HumAID\\hurricane_harvey_2017\\hurricane...      6378   \n",
       "6  Dataset\\HumAID\\hurricane_irma_2017\\hurricane_i...      6579   \n",
       "\n",
       "   avg_req_tokens  est_total_tokens  fits_cap  limit_used_%  \n",
       "8             440            675840      True          33.8  \n",
       "1             439            688791      True          34.4  \n",
       "2             461           1269133      True          63.5  \n",
       "4             455           1994720     False          99.7  \n",
       "7             442           2251548     False         112.6  \n",
       "0             451           2328513     False         116.4  \n",
       "3             455           2424695     False         121.2  \n",
       "9             460           2570480     False         128.5  \n",
       "5             440           2806320     False         140.3  \n",
       "6             440           2894760     False         144.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK to run with Tier-1 key:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>split</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>est_total_tokens</th>\n",
       "      <th>limit_used_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaikoura_earthquake_2016</td>\n",
       "      <td>train</td>\n",
       "      <td>1536</td>\n",
       "      <td>675840</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>canada_wildfires_2016</td>\n",
       "      <td>train</td>\n",
       "      <td>1569</td>\n",
       "      <td>688791</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cyclone_idai_2019</td>\n",
       "      <td>train</td>\n",
       "      <td>2753</td>\n",
       "      <td>1269133</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      event  split  num_rows  est_total_tokens  limit_used_%\n",
       "0  kaikoura_earthquake_2016  train      1536            675840          33.8\n",
       "1     canada_wildfires_2016  train      1569            688791          34.4\n",
       "2         cyclone_idai_2019  train      2753           1269133          63.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too big for Tier-1 (use alternate key):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>split</th>\n",
       "      <th>num_rows</th>\n",
       "      <th>est_total_tokens</th>\n",
       "      <th>limit_used_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurricane_florence_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>4384</td>\n",
       "      <td>1994720</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hurricane_maria_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>5094</td>\n",
       "      <td>2251548</td>\n",
       "      <td>112.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california_wildfires_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>5163</td>\n",
       "      <td>2328513</td>\n",
       "      <td>116.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hurricane_dorian_2019</td>\n",
       "      <td>train</td>\n",
       "      <td>5329</td>\n",
       "      <td>2424695</td>\n",
       "      <td>121.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kerala_floods_2018</td>\n",
       "      <td>train</td>\n",
       "      <td>5588</td>\n",
       "      <td>2570480</td>\n",
       "      <td>128.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hurricane_harvey_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>6378</td>\n",
       "      <td>2806320</td>\n",
       "      <td>140.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurricane_irma_2017</td>\n",
       "      <td>train</td>\n",
       "      <td>6579</td>\n",
       "      <td>2894760</td>\n",
       "      <td>144.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       event  split  num_rows  est_total_tokens  limit_used_%\n",
       "0    hurricane_florence_2018  train      4384           1994720          99.7\n",
       "1       hurricane_maria_2017  train      5094           2251548         112.6\n",
       "2  california_wildfires_2018  train      5163           2328513         116.4\n",
       "3      hurricane_dorian_2019  train      5329           2424695         121.2\n",
       "4         kerala_floods_2018  train      5588           2570480         128.5\n",
       "5      hurricane_harvey_2017  train      6378           2806320         140.3\n",
       "6        hurricane_irma_2017  train      6579           2894760         144.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- discover datasets ---\n",
    "def discover_tsvs(base: Path, splits: list[str]):\n",
    "    items = []\n",
    "    for event_dir in sorted([p for p in base.iterdir() if p.is_dir()]):\n",
    "        event = event_dir.name\n",
    "        for split in splits:\n",
    "            tsv = event_dir / f\"{event}_{split}.tsv\"\n",
    "            if tsv.exists():\n",
    "                items.append({\"event\": event, \"split\": split, \"tsv\": str(tsv)})\n",
    "    return pd.DataFrame(items)\n",
    "\n",
    "df_sources = discover_tsvs(BASE, SPLITS)\n",
    "\n",
    "# --- token budgeting ---\n",
    "token_index = build_token_index(\n",
    "    df_sources,\n",
    "    model=MODEL,\n",
    "    rules_text=RULES,\n",
    "    batch_token_limit=BATCH_TOKEN_LIMIT,\n",
    "    safety_margin=SAFETY_MARGIN,\n",
    "    sample_size=200,\n",
    "    max_output_tokens=MAX_OUTPUT_TOKENS,\n",
    ")\n",
    "\n",
    "display(token_index)\n",
    "\n",
    "df_fit     = token_index[token_index[\"fits_cap\"]].reset_index(drop=True)\n",
    "df_too_big = token_index[~token_index[\"fits_cap\"]].reset_index(drop=True)\n",
    "\n",
    "print(\"OK to run with Tier-1 key:\")\n",
    "display(df_fit[[\"event\",\"split\",\"num_rows\",\"est_total_tokens\",\"limit_used_%\"]])\n",
    "\n",
    "print(\"Too big for Tier-1 (use alternate key):\")\n",
    "display(df_too_big[[\"event\",\"split\",\"num_rows\",\"est_total_tokens\",\"limit_used_%\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65756c83-115c-4d1e-b0eb-45e64c91a8e8",
   "metadata": {},
   "source": [
    "# 2) Run all datasets (sequentially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac203b-d309-46a0-ab7c-633e83ac1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using Tier-1 key (OPENAI_API_KEY_1)\n",
      "\n",
      "=== Running kaikoura_earthquake_2016/train (gpt-4o-mini | modeS-RULES1-TIER1) ===\n",
      "Macro-F1 (tiny sample): 0.7341269841269842\n",
      "[batch batch_68f83249c27c8190bdafcf0f44367b82] status = validating\n"
     ]
    }
   ],
   "source": [
    "# --- helpers to run a list of datasets ---\n",
    "def run_list(dflist: pd.DataFrame, rules_text: str, model: str, tag: str):\n",
    "    results = []\n",
    "    for _, row in dflist.iterrows():\n",
    "        event, split, tsv = row[\"event\"], row[\"split\"], row[\"tsv\"]\n",
    "        print(f\"\\n=== Running {event}/{split} ({model} | {tag}) ===\")\n",
    "        try:\n",
    "            plan, preds, summary = run_experiment(\n",
    "                dataset_path=tsv,\n",
    "                rules=rules_text,\n",
    "                model=model,\n",
    "                tag=tag,\n",
    "                dryrun_n=DRYRUN_N,\n",
    "                poll_secs=POLL_SECS,\n",
    "                out_root=OUT_ROOT,\n",
    "                do_analysis=DO_ANALYSIS,\n",
    "            )\n",
    "            results.append({\n",
    "                \"event\": event,\n",
    "                \"split\": split,\n",
    "                \"run_dir\": str(plan[\"dir\"]),\n",
    "                \"predictions_csv\": str(plan[\"predictions_csv\"]),\n",
    "                \"macro_f1\": summary.get(\"macro_f1\"),\n",
    "                \"accuracy\": summary.get(\"accuracy\"),\n",
    "                \"num_total\": summary.get(\"num_total_with_truth\"),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {event}/{split}: {e}\")\n",
    "            results.append({\n",
    "                \"event\": event,\n",
    "                \"split\": split,\n",
    "                \"run_dir\": \"ERROR\",\n",
    "                \"predictions_csv\": \"\",\n",
    "                \"macro_f1\": float(\"nan\"),\n",
    "                \"accuracy\": float(\"nan\"),\n",
    "                \"num_total\": 0,\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# --- 1) Use OPENAI_API_KEY_1 for smaller datasets ---\n",
    "with use_api_key_env(\"OPENAI_API_KEY_1\"):\n",
    "    print(\">>> Using Tier-1 key (OPENAI_API_KEY_1)\")\n",
    "    df_runs_small = run_list(df_fit, RULES, MODEL, tag=f\"{TAG}-TIER1\")\n",
    "    display(df_runs_small)\n",
    "\n",
    "# --- 2) Use OPENAI_API_KEY_2 for larger datasets ---\n",
    "if not df_too_big.empty:\n",
    "    with use_api_key_env(\"OPENAI_API_KEY_2\"):\n",
    "        print(\">>> Using alternate key (OPENAI_API_KEY_2)\")\n",
    "        df_runs_big = run_list(df_too_big, RULES, MODEL, tag=f\"{TAG}-ALT\")\n",
    "        display(df_runs_big)\n",
    "else:\n",
    "    df_runs_big = pd.DataFrame()\n",
    "    print(\"No large datasets; nothing to run with the alternate key.\")\n",
    "\n",
    "# (optional) save an index of what ran under which key\n",
    "from datetime import datetime\n",
    "idx_dir = Path(OUT_ROOT) / \"_indexes\"\n",
    "idx_dir.mkdir(parents=True, exist_ok=True)\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "df_runs_small.assign(key=\"OPENAI_API_KEY_1\").to_csv(idx_dir / f\"runs_tier1_{MODEL}_{TAG}_{stamp}.csv\", index=False)\n",
    "if not df_runs_big.empty:\n",
    "    df_runs_big.assign(key=\"OPENAI_API_KEY_2\").to_csv(idx_dir / f\"runs_alt_{MODEL}_{TAG}_{stamp}.csv\", index=False)\n",
    "print(\"Saved run indexes in:\", idx_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ca66a-1e30-4908-99ab-8b6e2c9f89bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
